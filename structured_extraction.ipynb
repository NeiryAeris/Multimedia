{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages importing\n",
    "#### this action should be done 1 time only cus it took pretty long to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.applications import VGG16, vgg16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "#-------------------Search served packages#-------------------\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initating Configs\n",
    "- these configuration should run 1 time only\n",
    "- `BATCH_SIZE`: this set to 32 seems to be an ideal choice\n",
    "- `IMG_SIZE`: the images size should be resize, crops, etc to the declared size since all of the process require ``(224x224)`` image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"images\"\n",
    "# DB_PATH = \"./Database/structured_features.db\"\n",
    "DB_PATH = \"./Database/structured_features_ver2.db\"\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "# JSON_OUTPUT = \"./inspection/image_features_sample.json\"\n",
    "JSON_OUTPUT = \"./inspection/image_features_sample_ver2.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enviroment** config loading and feature **model** loading funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_environment():\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "def load_feature_model():\n",
    "    return VGG16(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database init and features storing queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS image_features (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            image_path TEXT,\n",
    "            label TEXT,\n",
    "            color_histogram TEXT,\n",
    "            shape_descriptor TEXT,\n",
    "            texture_descriptor TEXT,\n",
    "            deep_embedding TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    return conn, c\n",
    "\n",
    "def insert_features(cursor, data):\n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT INTO image_features (\n",
    "            image_path, label, color_histogram, shape_descriptor, texture_descriptor, deep_embedding\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", data)\n",
    "\n",
    "def save_sample(cursor):\n",
    "    cursor.execute(\"SELECT * FROM image_features LIMIT 10;\")\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    with open(JSON_OUTPUT, \"w\") as f:\n",
    "        json.dump([dict(zip(columns, row)) for row in rows], f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Images loading function\n",
    "- Image batch preparing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = load_img(path, target_size=IMG_SIZE)\n",
    "    return img_to_array(img)\n",
    "\n",
    "def preprocess_batch(images):\n",
    "    return preprocess_input(np.array(images)).astype(\"float16\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are functions that extract features like `color`, `shape`, `texture`.\n",
    "Values extracted by functions below will differ than what `VGG16` extract from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_color_histogram(img, bins=32): # might be a better alternative\n",
    "#     hist = np.histogram(img, bins=bins, range=(0, 256))[0]\n",
    "#     return (hist / hist.sum()).tolist()\n",
    "\n",
    "# def extract_shape_descriptor(img): # might be a better alternative\n",
    "#     return (img.mean(axis=2).flatten()[:32] / 255.0).tolist()\n",
    "\n",
    "# def extract_texture_descriptor(img): # could use Gabor filters, Haralick features, or GLCM if want more robust texture features\n",
    "#     gray = rgb2gray(img.astype(\"uint8\"))\n",
    "#     lbp = local_binary_pattern(gray, P=8, R=1.0)\n",
    "#     hist, _ = np.histogram(lbp, bins=32, range=(0, 256))\n",
    "#     return (hist / hist.sum()).tolist()\n",
    "\n",
    "# Enhanced features extraction\n",
    "\n",
    "def extract_color_histogram(img, bins=32):\n",
    "    hsv = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2HSV)\n",
    "    h_hist = np.histogram(hsv[:, :, 0], bins=bins, range=(0, 180))[0]\n",
    "    s_hist = np.histogram(hsv[:, :, 1], bins=bins, range=(0, 256))[0]\n",
    "    v_hist = np.histogram(hsv[:, :, 2], bins=bins, range=(0, 256))[0]\n",
    "    hist = np.concatenate([h_hist, s_hist, v_hist])\n",
    "    return (hist / hist.sum()).tolist()\n",
    "\n",
    "def extract_shape_descriptor(img):\n",
    "    gray = cv2.cvtColor(img.astype(\"uint8\"), cv2.COLOR_RGB2GRAY)\n",
    "    moments = cv2.moments(gray)\n",
    "    hu = cv2.HuMoments(moments).flatten()\n",
    "    return np.log1p(np.abs(hu)).tolist()\n",
    "\n",
    "def extract_texture_descriptor(img): # could use Gabor filters, Haralick features, or GLCM if want more robust texture features\n",
    "    gray = rgb2gray(img.astype(\"uint8\"))\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1.0)\n",
    "    hist, _ = np.histogram(lbp, bins=32, range=(0, 256))\n",
    "    return (hist / hist.sum()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features():\n",
    "    configure_environment()\n",
    "    model = load_feature_model()\n",
    "    conn, c = init_db()\n",
    "\n",
    "    image_batch, path_batch, label_batch, raw_images = [], [], [], []\n",
    "\n",
    "    for class_dir in os.listdir(ROOT_DIR):\n",
    "        class_path = os.path.join(ROOT_DIR, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for image_file in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            img = load_image(image_path)\n",
    "            raw_images.append(img)\n",
    "            image_batch.append(img)\n",
    "            path_batch.append(image_path)\n",
    "            label_batch.append(class_dir)\n",
    "\n",
    "            if len(image_batch) == BATCH_SIZE:\n",
    "                process_and_store_batch(model, image_batch, raw_images, path_batch, label_batch, c)\n",
    "                image_batch, path_batch, label_batch, raw_images = [], [], [], []\n",
    "\n",
    "    if image_batch:\n",
    "        process_and_store_batch(model, image_batch, raw_images, path_batch, label_batch, c)\n",
    "\n",
    "    save_sample(c)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def process_and_store_batch(model, image_batch, raw_images, path_batch, label_batch, cursor):\n",
    "    batch_np = preprocess_batch(image_batch)\n",
    "    features = model.predict(batch_np, verbose=0)\n",
    "\n",
    "    insert_data = []\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        img_raw = raw_images[i]\n",
    "        color_hist = extract_color_histogram(img_raw)\n",
    "        shape_desc = extract_shape_descriptor(img_raw)\n",
    "        texture_desc = extract_texture_descriptor(img_raw)\n",
    "        deep_embed = features[i].flatten().tolist()\n",
    "\n",
    "        insert_data.append((\n",
    "            path_batch[i],\n",
    "            label_batch[i],\n",
    "            json.dumps(color_hist),\n",
    "            json.dumps(shape_desc),\n",
    "            json.dumps(texture_desc),\n",
    "            json.dumps(deep_embed)\n",
    "        ))\n",
    "\n",
    "    insert_features(cursor, insert_data)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Lab/PythonProjects/Multimedia/venv/lib/python3.12/site-packages/skimage/feature/texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     extract_features()\n",
    "\n",
    "extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sections below will be the searching for similarity.\n",
    "The **input** will be:\n",
    "- Image from **outside** the dataset\n",
    "- Image from **inside** the dataset\n",
    "The **outputs** will be:\n",
    "    - **3** Images with **highest** similarities\n",
    "    - Similarities include **4** features vector:\n",
    "        - Color\n",
    "        - Shape\n",
    "        - Texture\n",
    "        - Embeded (Extracted by using VGG16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages importing\n",
    "#### this action should be done 1 time only cus it took TOO LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K # type: ignore\n",
    "from tensorflow.keras import mixed_precision # type: ignore\n",
    "from tensorflow.keras.applications import VGG16, vgg16 # type: ignore\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array # type: ignore\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "\n",
    "#-------------------Search served packages#-------------------\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initating Configs\n",
    "- these configuration should run 1 time only\n",
    "- `BATCH_SIZE`: this set to 32 seems to be an ideal choice\n",
    "- `IMG_SIZE`: the images size should be resize, crops, etc to the declared size since all of the process require ``(224x224)`` image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"./Raw\"\n",
    "DB_PATH = \"./Database/structured_features_ver3.db\"\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "JSON_OUTPUT = \"./inspection/image_features_sample_ver3.json\"\n",
    "CACHE_DIR = \"cache\"\n",
    "TREES_FILE = os.path.join(CACHE_DIR, \"balltrees_ver2.pkl\")\n",
    "ARRAYS_FILE = os.path.join(CACHE_DIR, \"arrays_ver2.pkl\")\n",
    "PATHS_FILE = os.path.join(CACHE_DIR, \"image_paths_ver2.pkl\")\n",
    "META_FILE = os.path.join(CACHE_DIR, \"meta_ver2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enviroment** config loading and feature **model** loading funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_environment():\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "def load_feature_model():\n",
    "    return VGG16(weights=\"imagenet\", include_top=False, pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database init and features storing queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS image_features (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            image_path TEXT,\n",
    "            label TEXT,\n",
    "            color_histogram TEXT,\n",
    "            shape_descriptor TEXT,\n",
    "            texture_descriptor TEXT,\n",
    "            deep_embedding TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    return conn, c\n",
    "\n",
    "def insert_features(cursor, data):\n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT INTO image_features (\n",
    "            image_path, label, color_histogram, shape_descriptor, texture_descriptor, deep_embedding\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", data)\n",
    "\n",
    "def save_sample(cursor):\n",
    "    cursor.execute(\"SELECT * FROM image_features LIMIT 10;\")\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    with open(JSON_OUTPUT, \"w\") as f:\n",
    "        json.dump([dict(zip(columns, row)) for row in rows], f, indent=4)\n",
    "        \n",
    "def load_database_features():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT image_path, color_histogram, shape_descriptor, texture_descriptor, deep_embedding FROM image_features\")\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    image_paths = []\n",
    "    color_features = []\n",
    "    shape_features = []\n",
    "    texture_features = []\n",
    "    deep_features = []\n",
    "\n",
    "    for row in rows:\n",
    "        image_paths.append(row[0])\n",
    "        color_features.append(json.loads(row[1]))\n",
    "        shape_features.append(json.loads(row[2]))\n",
    "        texture_features.append(json.loads(row[3]))\n",
    "        deep_features.append(json.loads(row[4]))\n",
    "\n",
    "    return image_paths, np.array(color_features), np.array(shape_features), np.array(texture_features), np.array(deep_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Images loading function\n",
    "- Image batch preparing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = load_img(path, target_size=IMG_SIZE)\n",
    "    return img_to_array(img)\n",
    "\n",
    "def preprocess_batch(images):\n",
    "    return preprocess_input(np.array(images)).astype(\"float16\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are functions that extract features like `color`, `shape`, `texture`.\n",
    "Values extracted by functions below will differ than what `VGG16` extract from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_object(img, output_size=(128, 128)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        return cv2.resize(img, output_size)\n",
    "\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.float32(sorted(box, key=lambda p: (p[1], p[0])))  # y,x order\n",
    "\n",
    "    dst_pts = np.float32([[0, 0], [output_size[0]-1, 0], [output_size[0]-1, output_size[1]-1], [0, output_size[1]-1]])\n",
    "    M = cv2.getPerspectiveTransform(box, dst_pts)\n",
    "    warped = cv2.warpPerspective(img, M, output_size)\n",
    "    return warped\n",
    "\n",
    "\n",
    "def extract_color_histogram(img, bins=32):\n",
    "    hsv = cv2.cvtColor(img.astype(\"uint8\"), cv2.COLOR_RGB2HSV)\n",
    "    h_hist = np.histogram(hsv[:, :, 0], bins=bins, range=(0, 180))[0]\n",
    "    s_hist = np.histogram(hsv[:, :, 1], bins=bins, range=(0, 256))[0]\n",
    "    v_hist = np.histogram(hsv[:, :, 2], bins=bins, range=(0, 256))[0]\n",
    "    hist = np.concatenate([h_hist, s_hist, v_hist])\n",
    "    return (hist / hist.sum()).tolist()\n",
    "\n",
    "\n",
    "def extract_hog(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    (fd, hog_image) = hog(\n",
    "        gray_image,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(1, 1),\n",
    "        visualize=True,\n",
    "        block_norm=\"L2\",\n",
    "    )\n",
    "    return fd\n",
    "\n",
    "\n",
    "def extract_rgb(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    hist_rgb = cv2.calcHist(\n",
    "        [image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]\n",
    "    )\n",
    "    cv2.normalize(hist_rgb, hist_rgb)\n",
    "    return hist_rgb.flatten()\n",
    "\n",
    "\n",
    "def extract_hog_rgb(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    hist_rgb = cv2.calcHist(\n",
    "        [image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]\n",
    "    )\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fd, hog_image = hog(\n",
    "        gray_image,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(1, 1),\n",
    "        visualize=True,\n",
    "        block_norm=\"L2\",\n",
    "    )\n",
    "    cv2.normalize(hist_rgb, hist_rgb)\n",
    "    combined_features = np.concatenate((fd, hist_rgb.flatten()))\n",
    "    return combined_features\n",
    "\n",
    "\n",
    "def extract_shape_descriptor(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    norm_img = normalize_object(image, output_size=(128, 128))\n",
    "    gray = cv2.cvtColor(norm_img.astype(\"uint8\"), cv2.COLOR_BGR2GRAY)\n",
    "    moments = cv2.moments(gray)\n",
    "    hu = cv2.HuMoments(moments).flatten()\n",
    "    return np.log1p(np.abs(hu)).tolist()\n",
    "\n",
    "def extract_hog_hu(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Extract HOG features\n",
    "    hog_features, _ = hog(\n",
    "        gray,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(1, 1),\n",
    "        visualize=True,\n",
    "        block_norm=\"L2\",\n",
    "    )\n",
    "\n",
    "    # Extract Hu Moments\n",
    "    moments = cv2.moments(gray)\n",
    "    hu_moments = cv2.HuMoments(moments).flatten()\n",
    "    hu_moments = np.log1p(np.abs(hu_moments))  # Stability for large values\n",
    "\n",
    "    # Combine features\n",
    "    combined = np.concatenate([hog_features, hu_moments])\n",
    "    return combined\n",
    "\n",
    "\n",
    "def extract_texture_descriptor(img):\n",
    "    gray = rgb2gray(img.astype(\"uint8\"))\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1.0)\n",
    "    hist, _ = np.histogram(lbp, bins=32, range=(0, 256))\n",
    "    return (hist / hist.sum()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features():\n",
    "    configure_environment()\n",
    "    model = load_feature_model()\n",
    "    conn, c = init_db()\n",
    "\n",
    "    image_batch, path_batch, label_batch, raw_images = [], [], [], []\n",
    "\n",
    "    for class_dir in os.listdir(ROOT_DIR):\n",
    "        class_path = os.path.join(ROOT_DIR, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for image_file in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            img = load_image(image_path)\n",
    "            raw_images.append(img)\n",
    "            image_batch.append(img)\n",
    "            path_batch.append(image_path)\n",
    "            label_batch.append(class_dir)\n",
    "\n",
    "            if len(image_batch) == BATCH_SIZE:\n",
    "                process_and_store_batch(\n",
    "                    model, image_batch, raw_images, path_batch, label_batch, c\n",
    "                )\n",
    "                image_batch, path_batch, label_batch, raw_images = [], [], [], []\n",
    "\n",
    "    if image_batch:\n",
    "        process_and_store_batch(\n",
    "            model, image_batch, raw_images, path_batch, label_batch, c\n",
    "        )\n",
    "\n",
    "    save_sample(c)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def process_and_store_batch(\n",
    "    model, image_batch, raw_images, path_batch, label_batch, cursor\n",
    "):\n",
    "    batch_np = preprocess_batch(image_batch)\n",
    "    features = model.predict(batch_np, verbose=0)\n",
    "\n",
    "    insert_data = []\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        img_raw = raw_images[i]\n",
    "        color_hist = extract_color_histogram(img_raw)\n",
    "        shape_desc = extract_shape_descriptor(img_raw)\n",
    "        texture_desc = extract_texture_descriptor(img_raw)\n",
    "        deep_embed = features[i].flatten().tolist()\n",
    "\n",
    "        insert_data.append(\n",
    "            (\n",
    "                path_batch[i],\n",
    "                label_batch[i],\n",
    "                json.dumps(color_hist),\n",
    "                json.dumps(shape_desc),\n",
    "                json.dumps(texture_desc),\n",
    "                json.dumps(deep_embed),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    insert_features(cursor, insert_data)\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Lab/PythonProjects/Multimedia/venv/lib/python3.12/site-packages/skimage/feature/texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     extract_features()\n",
    "\n",
    "extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sections below will be the searching for similarity.\n",
    "The **input** will be:\n",
    "- Image from **outside** the dataset\n",
    "- Image from **inside** the dataset\n",
    "The **outputs** will be:\n",
    "    - **3** Images with **highest** similarities\n",
    "    - Similarities include **4** features vector:\n",
    "        - Color\n",
    "        - Shape\n",
    "        - Texture\n",
    "        - Embeded (Extracted by using VGG16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
